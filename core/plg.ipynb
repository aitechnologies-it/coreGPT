{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 12:21:03.914451: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Union\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_core as K\n",
    "from keras_core import layers\n",
    "from keras_core import losses\n",
    "from keras_core import metrics\n",
    "from keras_core import optimizers\n",
    "from keras_core import initializers\n",
    "import keras_nlp\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "train_path = os.path.join(data_dir, \"shakespeare/train.bin\")\n",
    "val_path = os.path.join(data_dir, \"shakespeare/val.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    # GPT configs\n",
    "    block_size: int = 64 # 1024\n",
    "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    n_layer: int = 4 # 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 256 # 768\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "    layer_norm_epsilon: float = 1e-05\n",
    "\n",
    "    # Train configs\n",
    "    batch_size = 16\n",
    "    weight_decay = 1e-01\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.95\n",
    "    decay_lr = True # whether to decay the learning rate\n",
    "    warmup_iters = 100 # 2000 # how many steps to warm up for\n",
    "\n",
    "config = GPTConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(layers.Layer):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ln1 = layers.LayerNormalization(epsilon=config.layer_norm_epsilon) # TODO: bias?\n",
    "        self.ln2 = layers.LayerNormalization(epsilon=config.layer_norm_epsilon)\n",
    "        mha = layers.MultiHeadAttention(num_heads=config.n_head, key_dim=config.n_embd // config.n_head)\n",
    "        self.attn = lambda x, training: mha(x, x, training=training, use_causal_mask=True)\n",
    "        self.mlp = K.Sequential([\n",
    "            layers.Dense(\n",
    "                units=4*config.n_embd, use_bias=True, activation=\"gelu\",\n",
    "                kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.02),\n",
    "                bias_initializer=initializers.Zeros(),\n",
    "            ),\n",
    "            layers.Dense(\n",
    "                units=config.n_embd, use_bias=True,\n",
    "                kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.02),\n",
    "                bias_initializer=initializers.Zeros(),\n",
    "            ),\n",
    "            layers.Dropout(config.dropout)\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        x = x + self.attn(self.ln1(x), training=training)\n",
    "        x = x + self.mlp(self.ln2(x), training=training)\n",
    "        return x\n",
    "    \n",
    "class GPT(K.Model):\n",
    "    def __init__(self, config: GPTConfig, **kwargs):\n",
    "        super().__init__(name=\"coreGPT\", **kwargs)\n",
    "        self.config = config\n",
    "\n",
    "        # input embedding\n",
    "        self.emb = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "            vocabulary_size=config.vocab_size,\n",
    "            sequence_length=config.block_size,\n",
    "            embedding_dim=config.n_embd,\n",
    "            embeddings_initializer=initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "        )\n",
    "        self.drop = layers.Dropout(config.dropout)\n",
    "        # transformer blocks\n",
    "        self.blocks = [Block(config) for _ in range(config.n_layer)]\n",
    "        # decoder head\n",
    "        self.ln_f = layers.LayerNormalization(axis=-1)\n",
    "        self.head = layers.Dense(\n",
    "            units=config.vocab_size, use_bias=False,\n",
    "            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.02),\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        B, T = inputs.shape\n",
    "        # embed sentence\n",
    "        x = self.emb(inputs)\n",
    "        x = self.drop(x, training=training)\n",
    "        # attention\n",
    "        for block in self.blocks:\n",
    "            x = block(x, training=training)\n",
    "        # compute logits\n",
    "        x = self.ln_f(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "    \n",
    "    def summary(self):\n",
    "        x = K.Input(shape=[self.config.block_size], batch_size=config.batch_size, dtype=\"int32\")\n",
    "        dummy = K.Model(inputs=x, outputs=self.call(x), name=self.name)\n",
    "        return dummy.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"coreGPT\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"coreGPT\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ token_and_position_embedding_2  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,894,208</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)     │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ block_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Block</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">526,592</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ block_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Block</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">526,592</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ block_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Block</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">526,592</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ block_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Block</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">526,592</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ layer_normalization_26          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50304</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,877,824</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ token_and_position_embedding_2  │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │ \u001b[38;5;34m12,894,208\u001b[0m │\n",
       "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)     │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ block_8 (\u001b[38;5;33mBlock\u001b[0m)                 │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │    \u001b[38;5;34m526,592\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ block_9 (\u001b[38;5;33mBlock\u001b[0m)                 │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │    \u001b[38;5;34m526,592\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ block_10 (\u001b[38;5;33mBlock\u001b[0m)                │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │    \u001b[38;5;34m526,592\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ block_11 (\u001b[38;5;33mBlock\u001b[0m)                │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │    \u001b[38;5;34m526,592\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ layer_normalization_26          │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │        \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m50304\u001b[0m)           │ \u001b[38;5;34m12,877,824\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,878,912</span> (106.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,878,912\u001b[0m (106.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,878,912</span> (106.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,878,912\u001b[0m (106.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = K.Input(shape=[config.block_size], dtype=\"int32\")\n",
    "\n",
    "model = GPT(config)\n",
    "model.compile(\n",
    "    optimizer=optimizers.AdamW(learning_rate=6e-4, weight_decay=config.weight_decay),\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy(name='accuracy')],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.memmap(train_path, dtype=np.uint16, mode='r')\n",
    "val_data = np.memmap(val_path, dtype=np.uint16, mode='r')\n",
    "\n",
    "n_batch_train = (len(train_data)-config.block_size)//config.batch_size\n",
    "n_batch_val = (len(val_data)-config.block_size)//config.batch_size\n",
    "\n",
    "def get_windowed_tf_dataset(data: Union[np.memmap, np.array]):\n",
    "    x = (\n",
    "        tf.data.Dataset.from_tensor_slices(data[:-1])\n",
    "        .window(config.block_size, shift=1, stride=1, drop_remainder=True)\n",
    "        .flat_map(lambda x: x.batch(config.block_size))\n",
    "    )\n",
    "    y = (\n",
    "        tf.data.Dataset.from_tensor_slices(data[1:])\n",
    "        .window(config.block_size, shift=1, stride=1, drop_remainder=True)\n",
    "        .flat_map(lambda x: x.batch(config.block_size))\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        tf.data.Dataset\n",
    "        .zip((x, y))\n",
    "        .batch(batch_size=config.batch_size,\n",
    "               drop_remainder=True,\n",
    "               num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .repeat()\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "train_dataset = get_windowed_tf_dataset(train_data)\n",
    "val_dataset = get_windowed_tf_dataset(val_data)\n",
    "\n",
    "train_data, val_data = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 14:11:06.257060: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype uint16 and shape [316]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-09-18 14:11:06.257581: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype uint16 and shape [316]\n",
      "\t [[{{node Placeholder/_8}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7014 - loss: 1.0106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 14:11:26.672404: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype uint16 and shape [142]\n",
      "\t [[{{node Placeholder/_8}}]]\n",
      "2023-09-18 14:11:26.672965: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype uint16 and shape [142]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.7042 - loss: 1.0013 - val_accuracy: 0.0745 - val_loss: 9.3600\n",
      "Epoch 2/2\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.7630 - loss: 0.7862 - val_accuracy: 0.1067 - val_loss: 9.6398\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=n_batch_train,\n",
    "    epochs=2,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=n_batch_val,\n",
    "    verbose=1\n",
    ")\n",
    "    # batch_size=None,\n",
    "    # epochs=1,\n",
    "    # use_multiprocessing=True,\n",
    "    # verbose=\"auto\",\n",
    "    # callbacks=None,\n",
    "    # validation_split=0.0,\n",
    "    # validation_data=None,\n",
    "    # shuffle=True,\n",
    "    # class_weight=None,\n",
    "    # sample_weight=None,\n",
    "    # initial_epoch=0,\n",
    "    # steps_per_epoch=None,\n",
    "    # validation_batch_size=None,\n",
    "    # validation_freq=1,\n",
    "    # max_queue_size=10,\n",
    "    # workers=1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.7466796636581421, 0.799023449420929],\n",
       " 'loss': [0.8615785241127014, 0.6976556181907654],\n",
       " 'val_accuracy': [0.074462890625, 0.106689453125],\n",
       " 'val_loss': [9.359951972961426, 9.639775276184082]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vg/cjz3vt2s5szcrgwhqp9hfz9w0000gn/T/ipykernel_12910/4236967733.py:1: DeprecationWarning: This function is deprecated. Please call randint(0, 100 + 1) instead\n",
      "  inp = np.random.random_integers(0, 100, size=(1, config.n_seq,))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 256)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = np.random.random_integers(0, 100, size=(1, config.n_seq,))\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 256, 50304)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.predict(inp, batch_size=1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.29266614, -0.02570427, -0.08666821, ...,  0.2424404 ,\n",
       "       -0.1005659 ,  0.25224355], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.e+00, 0.e+00, 0.e+00, 0.e+00],\n",
       "        [1.e+02, 2.e+02, 3.e+02, 4.e+02],\n",
       "        [1.e-01, 3.e-01, 7.e-01, 9.e-01]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = np.array(\n",
    "    [\n",
    "        [\n",
    "            [0.0, 0.0, 0.0, 0.0],\n",
    "            [100, 200, 300, 400],\n",
    "            [0.1, 0.3, 0.7, 0.9],\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(inp.shape)\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[   0.      ,    0.      ,    0.      ,    0.      ],\n",
       "        [ -51.026886, -188.48923 ,   14.233276, -163.07217 ],\n",
       "        [ -50.939663, -188.4063  ,   14.111473, -163.03067 ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([inp], batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.ones(shape=(1, 50), dtype=\"int32\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
