{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 14:48:17.902270: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-20 14:48:17.959160: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Union\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "# import keras_nlp\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "dataset_name = \"shakespeare\"\n",
    "\n",
    "if os.environ[\"KERAS_BACKEND\"] == \"torch\":\n",
    "    token_dtype = np.int32\n",
    "    train_path = os.path.join(data_dir, dataset_name, \"train_int32.bin\")\n",
    "    val_path = os.path.join(data_dir, dataset_name, \"val_int32.bin\")\n",
    "else:\n",
    "    token_dtype = np.uint16\n",
    "    train_path = os.path.join(data_dir, dataset_name, \"train.bin\")\n",
    "    val_path = os.path.join(data_dir, dataset_name, \"val.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    # GPT configs\n",
    "    block_size: int = 512 # 1024\n",
    "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    n_layer: int = 8 # 12\n",
    "    n_head: int = 12\n",
    "    hidden_size: int = 512 # 768\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "    layer_norm_epsilon: float = 1e-05\n",
    "\n",
    "    # Train configs\n",
    "    n_epoch = 1\n",
    "    batch_size = 4\n",
    "    weight_decay = 1e-01\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.95\n",
    "    decay_lr = True # whether to decay the learning rate\n",
    "    warmup_iters = 100 # 2000 # how many steps to warm up for\n",
    "    verbose = 100 # 10\n",
    "\n",
    "config = GPTConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(layers.Layer):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ln1 = layers.LayerNormalization(epsilon=config.layer_norm_epsilon) # TODO: bias?\n",
    "        self.ln2 = layers.LayerNormalization(epsilon=config.layer_norm_epsilon)\n",
    "        mha = layers.MultiHeadAttention(num_heads=config.n_head, key_dim=config.hidden_size // config.n_head)\n",
    "        self.attn = lambda x, training: mha(x, x, training=training, use_causal_mask=True)\n",
    "        self.mlp = K.Sequential([\n",
    "            layers.Dense(\n",
    "                units=4*config.hidden_size, use_bias=True, activation=\"gelu\",\n",
    "                kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.02),\n",
    "                bias_initializer=initializers.Zeros(),\n",
    "            ),\n",
    "            layers.Dense(\n",
    "                units=config.hidden_size, use_bias=True,\n",
    "                kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.02),\n",
    "                bias_initializer=initializers.Zeros(),\n",
    "            ),\n",
    "            layers.Dropout(config.dropout)\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        x = x + self.attn(self.ln1(x), training=training)\n",
    "        x = x + self.mlp(self.ln2(x), training=training)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class GPT(K.Model):\n",
    "    def __init__(self, config: GPTConfig, **kwargs):\n",
    "        super().__init__(name=\"coreGPT\", **kwargs)\n",
    "        self.config = config\n",
    "\n",
    "        # input embedding\n",
    "        self.tok_emb = K.layers.Embedding(\n",
    "            input_dim=config.vocab_size, output_dim=config.hidden_size,\n",
    "            embeddings_initializer=K.initializers.RandomNormal(mean=0.0, stddev=0.02),\n",
    "            name=\"embedding\",\n",
    "        )\n",
    "        self.drop = layers.Dropout(config.dropout)\n",
    "        # transformer blocks\n",
    "        self.blocks = [Block(config) for _ in range(config.n_layer)]\n",
    "        # decoder head\n",
    "        self.ln_f = layers.LayerNormalization(axis=-1)\n",
    "        self.head = layers.Dense(\n",
    "            units=config.vocab_size, use_bias=False,\n",
    "            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.02),\n",
    "        )\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        self.pos_emb = self.add_weight(\n",
    "            name=\"positional\",\n",
    "            shape=(1, self.config.block_size, self.config.hidden_size),\n",
    "            initializer=K.initializers.RandomNormal(mean=0.0, stddev=0.02),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        B, T = inputs.shape\n",
    "        # embed sentence\n",
    "        wte = self.tok_emb(inputs)\n",
    "        wpe = self.pos_emb[:, :T, :]\n",
    "        x = self.drop(wte + wpe, training=training)\n",
    "        # attention\n",
    "        for block in self.blocks:\n",
    "            x = block(x, training=training)\n",
    "        # compute logits\n",
    "        x = self.ln_f(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "    \n",
    "    def summary(self):\n",
    "        x = K.Input(shape=[self.config.block_size], batch_size=self.config.batch_size, dtype=\"int32\")\n",
    "        dummy = K.Model(inputs=x, outputs=self.call(x), name=self.name)\n",
    "        return dummy.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = K.Input(shape=[config.block_size], dtype=\"int32\")\n",
    "\n",
    "model = GPT(config)\n",
    "model.build((config.batch_size, config.block_size))\n",
    "model.compile(\n",
    "    optimizer=optimizers.AdamW(learning_rate=6e-4, weight_decay=config.weight_decay),\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy(name='accuracy')],\n",
    ")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(config, train_path, val_path):\n",
    "    train_data = np.memmap(train_path, dtype=token_dtype, mode='r')\n",
    "    val_data = np.memmap(val_path, dtype=token_dtype, mode='r')\n",
    "\n",
    "    n_batch_train = (len(train_data)-config.block_size)//config.batch_size\n",
    "    n_batch_val = (len(val_data)-config.block_size)//config.batch_size\n",
    "\n",
    "    def get_windowed_tf_dataset(data: Union[np.memmap, np.array]):\n",
    "        x = (\n",
    "            tf.data.Dataset.from_tensor_slices(data[:-1])\n",
    "            .window(config.block_size, shift=1, stride=1, drop_remainder=True)\n",
    "            .flat_map(lambda x: x.batch(config.block_size))\n",
    "        )\n",
    "        y = (\n",
    "            tf.data.Dataset.from_tensor_slices(data[1:])\n",
    "            .window(config.block_size, shift=1, stride=1, drop_remainder=True)\n",
    "            .flat_map(lambda x: x.batch(config.block_size))\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            tf.data.Dataset\n",
    "            .zip((x, y))\n",
    "            .batch(batch_size=config.batch_size,\n",
    "                drop_remainder=True,\n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .repeat()\n",
    "            .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        )\n",
    "\n",
    "    train_dataset = get_windowed_tf_dataset(train_data)\n",
    "    val_dataset = get_windowed_tf_dataset(val_data)\n",
    "\n",
    "    return train_dataset, val_dataset, n_batch_train, n_batch_val\n",
    "\n",
    "train_dataset, val_dataset, n_batch_train, n_batch_val = load_data(config, train_path, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to \"build\" the model before fit()\n",
    "if os.environ[\"KERAS_BACKEND\"] == \"torch\":\n",
    "    inp = next(iter(train_dataset))[0]\n",
    "    _ = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  20/8427\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:46:42\u001b[0m 2s/step - accuracy: 0.1550 - loss: 7.8354"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/diego/nanoGPT-kerascore/core/plg.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     train_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49mn_batch_train,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mn_epoch,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mn_batch_val,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/backend/torch/trainer.py:295\u001b[0m, in \u001b[0;36mTorchTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39mfor\u001b[39;00m step, data \u001b[39min\u001b[39;00m epoch_iterator\u001b[39m.\u001b[39menumerate_epoch(return_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnp\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    292\u001b[0m     \u001b[39m# Callbacks\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 295\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(data)\n\u001b[1;32m    297\u001b[0m     \u001b[39m# Callbacks\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_end(step, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pythonify_logs(logs))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/backend/torch/trainer.py:100\u001b[0m, in \u001b[0;36mTorchTrainer.make_train_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m data \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 100\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(data)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/backend/torch/trainer.py:31\u001b[0m, in \u001b[0;36mTorchTrainer.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m# Compute predictions\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_has_training_arg:\n\u001b[0;32m---> 31\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     32\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/layers/layer.py:798\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    797\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 798\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m    800\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/backend/torch/layer.py:26\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mreturn\u001b[39;00m Operation\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/ops/operation.py:42\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         call_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall\n\u001b[1;32m     38\u001b[0m     call_fn \u001b[39m=\u001b[39m traceback_utils\u001b[39m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     39\u001b[0m         call_fn,\n\u001b[1;32m     40\u001b[0m         object_name\u001b[39m=\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.call()\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     41\u001b[0m     )\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m call_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     44\u001b[0m \u001b[39m# Plain flow.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:157\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    159\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    160\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[1;32m/home/diego/nanoGPT-kerascore/core/plg.ipynb Cell 9\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# attention\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m     x \u001b[39m=\u001b[39m block(x, training\u001b[39m=\u001b[39;49mtraining)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# compute logits\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_f(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/layers/layer.py:798\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    797\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 798\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m    800\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/backend/torch/layer.py:26\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mreturn\u001b[39;00m Operation\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/ops/operation.py:42\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         call_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall\n\u001b[1;32m     38\u001b[0m     call_fn \u001b[39m=\u001b[39m traceback_utils\u001b[39m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     39\u001b[0m         call_fn,\n\u001b[1;32m     40\u001b[0m         object_name\u001b[39m=\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.call()\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     41\u001b[0m     )\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m call_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     44\u001b[0m \u001b[39m# Plain flow.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:157\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    159\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    160\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[1;32m/home/diego/nanoGPT-kerascore/core/plg.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, x, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln1(x), training\u001b[39m=\u001b[39mtraining)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln2(x), training\u001b[39m=\u001b[39;49mtraining)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnova-vm/home/diego/nanoGPT-kerascore/core/plg.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/layers/layer.py:798\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    797\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 798\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m    800\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/backend/torch/layer.py:26\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mreturn\u001b[39;00m Operation\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/ops/operation.py:42\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         call_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall\n\u001b[1;32m     38\u001b[0m     call_fn \u001b[39m=\u001b[39m traceback_utils\u001b[39m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     39\u001b[0m         call_fn,\n\u001b[1;32m     40\u001b[0m         object_name\u001b[39m=\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.call()\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     41\u001b[0m     )\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m call_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     44\u001b[0m \u001b[39m# Plain flow.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:157\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    159\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    160\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/models/sequential.py:187\u001b[0m, in \u001b[0;36mSequential.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    186\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_functional:\n\u001b[0;32m--> 187\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional\u001b[39m.\u001b[39;49mcall(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[1;32m    189\u001b[0m     \u001b[39m# Fallback: Just apply the layer sequence.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[39m# This typically happens if `inputs` is a nested struct.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m    192\u001b[0m         \u001b[39m# During each iteration, `inputs` are the inputs to `layer`, and\u001b[39;00m\n\u001b[1;32m    193\u001b[0m         \u001b[39m# `outputs` are the outputs of `layer` applied to `inputs`. At the\u001b[39;00m\n\u001b[1;32m    194\u001b[0m         \u001b[39m# end of each iteration `inputs` is set to `outputs` to prepare for\u001b[39;00m\n\u001b[1;32m    195\u001b[0m         \u001b[39m# the next layer.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/models/functional.py:188\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m             x\u001b[39m.\u001b[39m_keras_mask \u001b[39m=\u001b[39m mask\n\u001b[0;32m--> 188\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_through_graph(\n\u001b[1;32m    189\u001b[0m     inputs, operation_fn\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m op: operation_fn(op, training\u001b[39m=\u001b[39;49mtraining)\n\u001b[1;32m    190\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[39mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/ops/function.py:128\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[0;34m(self, inputs, operation_fn)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mfill_in(tensor_dict)\n\u001b[0;32m--> 128\u001b[0m outputs \u001b[39m=\u001b[39m operation_fn(node\u001b[39m.\u001b[39;49moperation)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(node\u001b[39m.\u001b[39moutputs, tree\u001b[39m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/models/functional.py:574\u001b[0m, in \u001b[0;36moperation_fn.<locals>.call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    569\u001b[0m     \u001b[39mhasattr\u001b[39m(operation, \u001b[39m\"\u001b[39m\u001b[39m_call_has_training_arg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    570\u001b[0m     \u001b[39mand\u001b[39;00m operation\u001b[39m.\u001b[39m_call_has_training_arg\n\u001b[1;32m    571\u001b[0m     \u001b[39mand\u001b[39;00m training \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    572\u001b[0m ):\n\u001b[1;32m    573\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m training\n\u001b[0;32m--> 574\u001b[0m \u001b[39mreturn\u001b[39;00m operation(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/layers/layer.py:798\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    797\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 798\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m    800\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/backend/torch/layer.py:26\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mreturn\u001b[39;00m Operation\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/ops/operation.py:42\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         call_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall\n\u001b[1;32m     38\u001b[0m     call_fn \u001b[39m=\u001b[39m traceback_utils\u001b[39m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     39\u001b[0m         call_fn,\n\u001b[1;32m     40\u001b[0m         object_name\u001b[39m=\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.call()\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     41\u001b[0m     )\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m call_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     44\u001b[0m \u001b[39m# Plain flow.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:157\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    159\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    160\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/layers/core/dense.py:106\u001b[0m, in \u001b[0;36mDense.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m--> 106\u001b[0m     x \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mmatmul(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel)\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[1;32m    108\u001b[0m         x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/ops/numpy.py:3391\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m   3389\u001b[0m x1 \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mconvert_to_tensor(x1)\n\u001b[1;32m   3390\u001b[0m x2 \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mconvert_to_tensor(x2)\n\u001b[0;32m-> 3391\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mnumpy\u001b[39m.\u001b[39;49mmatmul(x1, x2)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/nanogpt/lib/python3.11/site-packages/keras_core/src/backend/torch/numpy.py:35\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmatmul\u001b[39m(x1, x2):\n\u001b[1;32m     34\u001b[0m     x1, x2 \u001b[39m=\u001b[39m convert_to_tensor(x1), convert_to_tensor(x2)\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmatmul(x1, x2)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=n_batch_train,\n",
    "    epochs=config.n_epoch,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=n_batch_val,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.7466796636581421, 0.799023449420929],\n",
       " 'loss': [0.8615785241127014, 0.6976556181907654],\n",
       " 'val_accuracy': [0.074462890625, 0.106689453125],\n",
       " 'val_loss': [9.359951972961426, 9.639775276184082]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vg/cjz3vt2s5szcrgwhqp9hfz9w0000gn/T/ipykernel_12910/4236967733.py:1: DeprecationWarning: This function is deprecated. Please call randint(0, 100 + 1) instead\n",
      "  inp = np.random.random_integers(0, 100, size=(1, config.n_seq,))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 256)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = np.random.random_integers(0, 100, size=(1, config.n_seq,))\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 256, 50304)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.predict(inp, batch_size=1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.29266614, -0.02570427, -0.08666821, ...,  0.2424404 ,\n",
       "       -0.1005659 ,  0.25224355], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.e+00, 0.e+00, 0.e+00, 0.e+00],\n",
       "        [1.e+02, 2.e+02, 3.e+02, 4.e+02],\n",
       "        [1.e-01, 3.e-01, 7.e-01, 9.e-01]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = np.array(\n",
    "    [\n",
    "        [\n",
    "            [0.0, 0.0, 0.0, 0.0],\n",
    "            [100, 200, 300, 400],\n",
    "            [0.1, 0.3, 0.7, 0.9],\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(inp.shape)\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[   0.      ,    0.      ,    0.      ,    0.      ],\n",
       "        [ -51.026886, -188.48923 ,   14.233276, -163.07217 ],\n",
       "        [ -50.939663, -188.4063  ,   14.111473, -163.03067 ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([inp], batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.ones(shape=(1, 50), dtype=\"int32\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
